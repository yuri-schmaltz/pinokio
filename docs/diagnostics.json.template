{
  "run": [
    {
      "type": "message",
      "text": "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\nâ•‘                   SYSTEM DIAGNOSTICS                            â•‘\nâ•‘                    Health & Performance Check                   â•‘\nâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    },
    {
      "type": "message",
      "text": "ðŸ“Š CPU & Memory Information:"
    },
    {
      "type": "shell",
      "command": "python3 -c \"import psutil; print(f'CPU Cores: {psutil.cpu_count()}'); print(f'CPU Usage: {psutil.cpu_percent()}%'); mem = psutil.virtual_memory(); print(f'Memory: {mem.used // (1024**3)}GB / {mem.total // (1024**3)}GB'); print(f'Available: {mem.available // (1024**3)}GB')\""
    },
    {
      "type": "message",
      "text": "ðŸ–¥ï¸  GPU Information:"
    },
    {
      "type": "shell",
      "command": "python3 -c \"import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA: {torch.version.cuda}'); print(f'Available: {torch.cuda.is_available()}'); print(f'Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \\\"CPU\\\"}'); print(f'VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB' if torch.cuda.is_available() else '')\" 2>/dev/null || echo 'âš ï¸  PyTorch/CUDA not available'"
    },
    {
      "type": "message",
      "text": "ðŸ’¾ Disk Space:"
    },
    {
      "type": "shell",
      "command": "df -h | grep -E '^/|Mounted'"
    },
    {
      "type": "message",
      "text": "ðŸ“¦ Python Packages:"
    },
    {
      "type": "shell",
      "command": "pip list 2>/dev/null | head -20 || echo 'pip list skipped'"
    },
    {
      "type": "message",
      "text": "âœ… Diagnostics complete. Review the output above for any issues."
    }
  ]
}
